{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import dct  # For Discrete Cosine Transform\n",
    "\n",
    "# Paths to your folders\n",
    "mfcc_folder = \"../Covid_19 Project/mfcc\"\n",
    "chroma_folder = \"../Covid_19 Project/chroma\"\n",
    "mel_folder = \"../Covid_19 Project/mel\"\n",
    "\n",
    "# Output CSV files\n",
    "mfcc_csv = \"mfcc.csv\"\n",
    "chroma_csv = \"chroma.csv\"\n",
    "mel_csv = \"mel.csv\"\n",
    "\n",
    "# Resize all images to a fixed size\n",
    "fixed_size = (128, 128)  # Ensure consistent dimensions\n",
    "\n",
    "# Number of coefficients to keep\n",
    "num_coefficients = 40  # Adjust based on your needs\n",
    "\n",
    "\n",
    "def extract_dct_features(folder, fixed_size, num_coefficients):\n",
    "    \"\"\"Process images and extract DCT coefficients.\"\"\"\n",
    "    data = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(file_path) and filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Read image as grayscale\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            # Resize to fixed size\n",
    "            img_resized = cv2.resize(img, fixed_size)\n",
    "            # Apply DCT\n",
    "            img_dct = dct(dct(img_resized.T, norm='ortho').T, norm='ortho')  # 2D DCT\n",
    "            # Flatten and select top coefficients\n",
    "            dct_flattened = img_dct.flatten()[:num_coefficients]\n",
    "            data.append(dct_flattened)\n",
    "            filenames.append(filename)  # Store the filename\n",
    "    return np.array(data), filenames\n",
    "\n",
    "\n",
    "# Process each folder and extract features\n",
    "mfcc_data, mfcc_filenames = extract_dct_features(mfcc_folder, fixed_size, num_coefficients)\n",
    "chroma_data, chroma_filenames = extract_dct_features(chroma_folder, fixed_size, num_coefficients)\n",
    "mel_data, mel_filenames = extract_dct_features(mel_folder, fixed_size, num_coefficients)\n",
    "\n",
    "# Save data to CSV files, including filenames\n",
    "mfcc_df = pd.DataFrame(mfcc_data, columns=[f\"coef_{i+1}\" for i in range(num_coefficients)])\n",
    "mfcc_df.insert(0, \"filename\", mfcc_filenames)\n",
    "mfcc_df.to_csv(mfcc_csv, index=False)\n",
    "\n",
    "chroma_df = pd.DataFrame(chroma_data, columns=[f\"coef_{i+1}\" for i in range(num_coefficients)])\n",
    "chroma_df.insert(0, \"filename\", chroma_filenames)\n",
    "chroma_df.to_csv(chroma_csv, index=False)\n",
    "\n",
    "mel_df = pd.DataFrame(mel_data, columns=[f\"coef_{i+1}\" for i in range(num_coefficients)])\n",
    "mel_df.insert(0, \"filename\", mel_filenames)\n",
    "mel_df.to_csv(mel_csv, index=False)\n",
    "\n",
    "print(\"Coefficient data with filenames saved to CSV files successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the image\n",
    "image = Image.open('../Covid_19 Project/mel/0b2f75d7-f116-4f35-ae4c-f2018eab2794.png')\n",
    "\n",
    "# Get the dimensions of the image\n",
    "width, height = image.size  # PIL returns width and height, no channels directly\n",
    "\n",
    "# Print the size\n",
    "print(f\"Width: {width}, Height: {height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read feature files\n",
    "mel_mean_feature = pd.read_csv('../Covid_19 Project/mel.csv')\n",
    "mfcc_mean_feature = pd.read_csv('../Covid_19 Project/mfcc.csv')\n",
    "chroma_mean_feature = pd.read_csv('../Covid_19 Project/chroma.csv')\n",
    "\n",
    "# Step 2: Concatenate features while excluding the first column (assumed to be a non-feature column)\n",
    "data2 = pd.concat([\n",
    "    mfcc_mean_feature.iloc[:, 1:],  # Exclude the first column (index)\n",
    "    chroma_mean_feature.iloc[:, 1:],  # Exclude the first column\n",
    "    mel_mean_feature.iloc[:, 1:-1]  # Exclude the first column\n",
    "], axis=1)\n",
    "\n",
    "# Step 3: Print the shape and preview of the concatenated features\n",
    "print(f\"Data shape after concatenation: {data2.shape}\")\n",
    "print(f\"First 4 rows of data:\\n {data2.head(4)}\")\n",
    "\n",
    "# Step 4: Load label file and convert to binary\n",
    "metadata_df = pd.read_csv('../Covid_19 Project/mel.csv')\n",
    "\n",
    "# Extract the label column (assumed to be the last column)\n",
    "labels = metadata_df.iloc[:, -1]\n",
    "\n",
    "# Convert labels to binary format (e.g., 'healthy' -> 0, 'COVID' -> 1)\n",
    "labels_binary = labels.map({'healthy': 0, 'COVID-19': 1})\n",
    "\n",
    "# Step 5: Add binary labels to the concatenated data\n",
    "data2['label'] = labels_binary.values\n",
    "\n",
    "# Step 6: Save the combined data with binary labels\n",
    "output_file = '../Covid_19 Project/combined_features_with_binary_labels.csv'\n",
    "data2.to_csv(output_file, index=False)\n",
    "\n",
    "# Final confirmation\n",
    "print(f\"Combined data with binary labels has been saved to {output_file}.\")\n",
    "print(f\"Final data shape: {data2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler,MinMaxScaler,scale\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold, cross_val_score, KFold,StratifiedKFold \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_curve,roc_auc_score, auc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "genre_list = data2.iloc[:, -1]\n",
    "#print ('genre_list\\n',genre_list)\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list) #Gán nhãn 0,1 cho class. Có thể nói là đưa về one hot coding\n",
    "neg, pos = np.bincount(y)\n",
    "total = neg + pos\n",
    "print ('positive: {} ({:.2f}% of total) \\nnegative cases: {}'.format(pos, 100 * pos/total ,neg)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "print ('X before scaling:\\n',np.array(data2.iloc[:, :-1]))\n",
    "X = scaler.fit_transform(np.array(data2.iloc[:, :-1], dtype = float)) #không scale 2 cột file name, label\n",
    "print ('\\nX after scaling:\\n',X,'\\nX.shape', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, \n",
    "                                                    random_state = None, stratify = y)\n",
    "#print (y_test)\n",
    "print (len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train.shape:',X_train.shape)\n",
    "print('\\nX_train.shape[1]:',X_train.shape[1])\n",
    "print ('\\ny_train.shape:',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],))) #Đầu vào đã được transpose\n",
    "\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer= keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "#Model này có dấu hiệu over fitting nên cho drop out\n",
    "\n",
    "# plot model\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "early_stopping_patience = 10\n",
    "\n",
    "# Add early stopping\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='./model_{epoch:02d}.h5', \n",
    "                                       save_freq='epoch', \n",
    "                                       save_best_only=True,\n",
    "                                       period = 10),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks = my_callbacks,\n",
    "                    validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa, librosa.display, os, csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "def history_loss_acc(history,name):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy_'+name)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss_'+name)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "history_loss_acc(history, 'Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "#print ('so predict:',len(predictions))\n",
    "#print('\\npredictions[0].shape',predictions[0].shape)\n",
    "#print('\\nnp.sum(predictions)',np.sum(predictions[0]))\n",
    "#print('\\npredictions[:4]\\n',predictions[:4])\n",
    "#print('\\ny_test',y_test[:4])\n",
    "y_predict =[]\n",
    "for i in range(len(predictions)):\n",
    "    predict = np.argmax(predictions[i])\n",
    "    y_predict.append(predict)\n",
    "#predict = np.argmax(predictions[4])\n",
    "#print ('predict\\n',y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_matrix(y_test, y_predict, name):\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    cm_df = pd.DataFrame(cm, index=[\"Negative\", \"Positive\"], columns=[\"Negative\", \"Positive\"])\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    sns.set(font_scale=1)\n",
    "\n",
    "    ax = sns.heatmap(cm_df, annot=True, square=True, fmt='d', linewidths=.2, cbar=0, cmap=plt.cm.Blues)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.tight_layout()\n",
    "    plt.title(name)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_test, y_predict, target_names=[\"Negative\", \"Positive\"]))\n",
    "    \n",
    "evaluate_matrix(y_test, y_predict, 'Original model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize score\n",
    "#print(predictions[:,1], '\\n',predictions[:,1].shape )\n",
    "def ROC_curve(y_test,predictions,name):\n",
    "    \n",
    "    # calculate roc curves\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, predictions[:,1])\n",
    "    print ('model: {} \\nAUC = {}'. format(name, auc(lr_fpr, lr_tpr)))\n",
    "    # plot the roc curve for the model\n",
    "    lw = 2\n",
    "    plt.plot(lr_fpr, lr_tpr, color=\"darkorange\",\n",
    "             lw=lw, label=\"ROC curve (area = %0.2f)\" % auc(lr_fpr, lr_tpr))\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([-0.02, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    # axis labels\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    plt.title(name)\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "\n",
    "ROC_curve(y_test,predictions,'Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('original positive cases: {}  and  total cases: {}'.format(pos, total) )\n",
    "# transform the dataset\n",
    "oversample = SMOTE(sampling_strategy=0.8, k_neighbors=5) #pos is equal to 50% neg\n",
    "X_os, y_os = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "order = np.arange(len(y_os))\n",
    "np.random.shuffle(order)\n",
    "X_os = X_os[order]\n",
    "y_os = y_os[order]\n",
    "\n",
    "neg_os, pos_os = np.bincount(y_os)\n",
    "total_os = neg_os + pos_os\n",
    "print ('\\nAfter oversampling \\nnegative cases: {}  \\npositive cases: {} ({:.2f}% of total)'.format(neg_os, pos_os, 100 * pos_os/total_os )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_os = model.fit(X_os, y_os,\n",
    "                    epochs=100,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks = my_callbacks,\n",
    "                    validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_loss_acc(history,'Original Data')\n",
    "history_loss_acc(history_os,'Oversampling Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_os, test_acc_os = model.evaluate(X_test,y_test) \n",
    "print ('test_acc_os',test_acc_os)\n",
    "predictions_os = model.predict(X_test)\n",
    "y_predict_os =[]\n",
    "for i in range(len(predictions_os)):\n",
    "    predict = np.argmax(predictions_os[i])\n",
    "    y_predict_os.append(predict)\n",
    "#predict = np.argmax(predictions[4])\n",
    "#print ('predict_os\\n',y_predict_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predictions = np.array([1 if x >= 0.5 else 0 for x in seed_final_test])\n",
    "evaluate_matrix(y_test, y_predict,'Original data')\n",
    "evaluate_matrix(y_test, y_predict_os, 'Oversampling Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_curve(y_test, predictions,'Original data')\n",
    "ROC_curve(y_test, predictions_os, 'Oversampling Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "loss_list = []\n",
    "\n",
    "# K-Fold CV\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "# We should use Stratified KFold for binary cassification & huge class imbalance\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_idx = 1\n",
    "\n",
    "for train_ids, val_ids in kfold.split(X_os, y_os):\n",
    "    \n",
    "    model = get_model()\n",
    "\n",
    "    print(\"\\nBắt đầu train Fold \", fold_idx)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_os[train_ids], y_os[train_ids],\n",
    "              batch_size=16,\n",
    "              epochs=25,\n",
    "              callbacks = my_callbacks,\n",
    "              verbose=1)\n",
    "\n",
    "\n",
    "    # Test và in kết quả\n",
    "    scores = model.evaluate(X_os[val_ids], y_os[val_ids], verbose=0)\n",
    "    print(\"Đã train xong Fold \", fold_idx)\n",
    "    print(f'> Fold {fold_idx} - Loss: {scores[0]} - Accuracy: {100* scores[1]}%')\n",
    "    \n",
    "    # Thêm thông tin accuracy và loss vào list\n",
    "    accuracy_list.append(scores[1] * 100)\n",
    "    loss_list.append(scores[0])\n",
    "\n",
    "    # To the next fold\n",
    "    fold_idx = fold_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In kết quả tổng thể\n",
    "print('* Chi tiết các fold')\n",
    "for i in range(0, len(accuracy_list)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_list[i]} - Accuracy: {accuracy_list[i]}%')\n",
    "\n",
    "print('* Đánh giá tổng thể các folds:')\n",
    "print(f'> Accuracy: {np.mean(accuracy_list)} (Độ lệch +- {np.std(accuracy_list)})')\n",
    "print(f'> Loss: {np.mean(loss_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history_cv = model.fit(X_os, y_os,\n",
    "          batch_size=16,\n",
    "          epochs=100,\n",
    "          callbacks = my_callbacks,\n",
    "          verbose=1)\n",
    "model.save('./kfold.h5')\n",
    "\n",
    "# load model and predict\n",
    "loaded_model = get_model()\n",
    "loaded_model.load_weights('./kfold.h5')\n",
    "predictions_cv = loaded_model.predict(X_test)\n",
    "y_predict_cv =[]\n",
    "for i in range(len(predictions_cv)):\n",
    "    predict = np.argmax(predictions_cv[i])\n",
    "    y_predict_cv.append(predict)\n",
    "#predict = np.argmax(predictions[4])\n",
    "#print ('predict_cv\\n',y_predict_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predictions = np.array([1 if x >= 0.5 else 0 for x in seed_final_test])\n",
    "evaluate_matrix(y_test, y_predict,'Original data')\n",
    "evaluate_matrix(y_test, y_predict_os, 'Oversampling Data')\n",
    "evaluate_matrix(y_test, y_predict_cv, 'Oversmap & K_fold')\n",
    "# summarize score\n",
    "ROC_curve(y_test, predictions,'Original data')\n",
    "ROC_curve(y_test, predictions_os, 'Oversampling Data')\n",
    "ROC_curve(y_test, predictions_cv, 'Oversamp & K_fold')\n",
    "\n",
    "#print('y_test ',y_test)\n",
    "#print('y_predict_origin_data ',y_predict)\n",
    "#print('y_predict_os ',y_predict_os)\n",
    "#print('y_predict_cv ',y_predict_cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
